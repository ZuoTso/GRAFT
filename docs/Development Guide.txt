✅1.先打通 pipelines/run_baseline_grape.py
    - 需要微調GRAPE，使輸出中間產物
        - X_norm
        - mask
        - split_idx
        - test 評估遮罩 (omega_test_idx)
            - 與train可能有重疊，若要更公正還要再整理，但會與GRAPE論文中的數據有差距
        - 原生二部圖(bipartite_edges.npz)
        - impute/...
        - label/...

✅2.建立主架構 pipelines/run_pipeline.py 當作統一入口

✅3.接上 lunar
    - 論文用 k=100，但論文的訓驗資料量大，以下根據比例做調整
    - k值選定，以及保留比例
        - 後續可以往交叉驗證發展
    - DEFAULTS = 
        {
            "yacht":   {"k": 20,  "keep": 0.95},✅✔️
            "housing": {"k": 25,  "keep": 0.95},✅✔️
            "energy":  {"k": 30,  "keep": 0.90},✅✔️
            "concrete":{"k": 35,  "keep": 0.90},✅
            "wine":    {"k": 40,  "keep": 0.80},✅✔️
            "kin8nm":  {"k": 100, "keep": 0.80},✅
            "power":   {"k": 100, "keep": 0.80},✅
            "naval":   {"k": 100, "keep": 0.80},✅
            "protein": {"k": 100, "keep": 0.70},✅
        }
    - shapes
        - concrete：1030 × 8。
        - energy：768 × 8（有兩個目標：Heating/Cooling Load）。
        - housing（Boston Housing）：506 × 13。
        - kin8nm：8192 × 8。
        - naval（Condition Based Monitoring of Naval Propulsion Plants）：11934 × 16。([archive.ics.uci.edu][1])
        - power（Combined Cycle Power Plant, CCPP）：9568 × 4。
        - protein（Physicochemical Properties of Protein Tertiary Structure / CASP）：45730 × 9。
        - wine（Wine Quality）：
            - red：1599 × 11；white：4898 × 11（GRAPE/常見基準多半用 red 版）。
        - yacht（Yacht Hydrodynamics）：308 × 6。

✅4.接上 t2g
    - T2G
    - adaptive edge weights
    - static edge topology
    - --t2gexp.epochs 0
        - epochs = 0（不訓練，僅 forward 匯權重）
            - 訊號來源：主要來自模型的初始結構偏好（初始化、正規化）＋資料本身的無監督統計（特徵共變、尺度等）。靜態拓樸參數未被學到，適應式邊多半反映資料局部關係。
            - 特性：計算快、零超參、不受標籤噪音影響；但分數可能較「粗」，對初始化/seed 較敏感。
            - 適配任務：對 GRAPE 的補值任務（impute） 反而常是合理的基線，因為補值重視特徵間的內在關聯，不需要 label 導引。
        - epochs > 0（輕量監督訓練後再匯權重）
            - 訊號來源：加入了目標 y 的監督訊號，GE/FR-Graph 會被推向「對任務有用的互動」。
            - 特性：分數更「任務導向」，通常對 label 預測 有利；但有過擬合風險（尤其資料小、噪音大），也更吃超參（lr、epochs、batch）。
            - 適配任務：對 GRAPE 的標籤預測（label） 常較有幫助；對 補值 未必更好（可能犧牲「普適關聯」去迎合 y）。

---

四種方法
✅1. LUNAR+GRAPE
✅2. T2G+GRAPE
✅3. LUNAR+T2G+GRAPE
✅4. T2G+LUNAR+GRAPE
四種 baseline
✅a. Ramdom drop ALL+GRAPE
✅b. Ramdom drop row+GRAPE
✅c. Ramdom drop col+GRAPE
✅d. GRAPE

評分指標 
    GRAPE論文中的評分指標imputation MAE
    Label prediction MAE
消融測試
    隨機剪枝
    上述的4種+GRAPE的組合
未來發展    
    LUNAR 保留比例


✅猜測：feature 太少 T2G 的效果不好
    我在嘗試更多的feature的時候出現的問題：
        當sample與feature多的時候，edge(n*d)數量遽增，需要的記憶體大小增加。
        使用 T2G 的 year 但 row 只取 40000：跑8小時20分
            使用相同的設定在 grape 以及 t2g_grape 測試猜想
    GRAPE 中的 mc 屬於 純feature imputation 沒有 label prediction
    以驗證有此趨勢
四種方法+四種baseline都完成
    dataset任選用原GRAPE(UCI)以及原T2G(sample有縮減，圖大大)
    方法LUNAR+GRAPE最好LUNAR+T2G 後GRAPE的兩總組合次之
    T2G的效益不大，因為UCI的特徵數少，如上述以驗證的猜測